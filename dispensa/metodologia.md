
---
title: Metodologia
author: Stefano Bussolon
description: ""
status: draft - publish
comments: true
date: 2018-10-17 14:07:08+00:00
layout: post
slug: metodologia
categories: 
tags: 
image: 

...

# Aspetti metodologici

## La ricerca

La ricerca scientifica è una attività strutturata, finalizzata ad accrescere la conoscenza, teorica e applicativa, attraverso un atteggiamento empirico. All’interno del processo di ricerca vi sono attività di acquisizione, analisi ed interpretazione dei dati. L’acquisizione è finalizzata a raccogliere i **dati**, l’analisi è finalizzata a trasformare i dati in **informazioni**, l’interpretazione a trasformare l’informazione in **conoscenza**.

La ricerca usa procedure, metodi e tecniche coerenti con una specifica scelta epistemologica e metodologica. Tali procedure, metodi e tecniche sono scelti in base alla loro validità e affidabilità. Infine, l’atteggiamento scientifico dovrebbe rispettare dei criteri di obiettività, ed evitare ogni forma di manipolazione finalizzata a *piegare* i risultati alle ipotesi del ricercatore. Uno dei fini dell’utilizzo di procedure, metodi e tecniche standardizzate è proprio quello di rispettare dei ragionevoli criteri di obiettività.

La ricerca scientifica, dunque, dovrebbe essere – nel limite del possibile – una attività controllata, rigorosa, sistematica, valida, verificabile, empirica, e critica.

### Attività controllata

Una delle finalità del metodo sperimentale è quella di misurare la relazione fra due variabili, minimizzando gli effetti di fattori estranei. Il criterio della controllabilità è più facile da ottenere quando l’attività di ricerca avviene in un contesto il più possibile controllato, quale il laboratorio sperimentale.

### Ricerca qualitativa

Lo svantaggio della ricerca in laboratorio, soprattutto nell’ambito delle scienze sociali e psicologiche, è che la controllabilità implica la semplificazione del setting. Per questo motivo, ad un approccio strettamente sperimentale e quantitativo, è spesso necessario affiancare delle attività di ricerca di tipo più qualitativo che, sebbene meno solide dal punto di vista inferenziale, possono permettere alla comunità scientifica di avere una più completa visione d’insieme, e possono permettere di meglio contestualizzare anche i risultati, più particolari, delle ricerche sperimentali più strettamente controllate e quantitative.

In termini epistemologici, questo atteggiamento viene definito *pluralismo metodologico*, mentre l’idea che un solo tipo di approccio empirico e conoscitivo sia possibile è definito *monismo metodologico*.

### Rigorosità

Il concetto di rigorosità si riferisce ad un atteggiamento epistemologico finalizzato ad identificare misure, strumenti e metodi che siano rilevanti, appropriati e giustificati (teoricamente ed empiricamente).

### Sistematicità

Indica che la procedura adottata segue una chiara sequenza logica.

### Atteggiamento critico

L’idea di atteggiamento critico, di sano scetticismo da parte del ricercatore, è la quintessenza del pensiero epistemologico di Popper. Secondo Popper la ricerca scientifica dovrebbe vivere di due momenti: *a* formulazione di ipotesi; *b* processo di falsificazione delle ipotesi. In questa prospettiva, è il ricercatore stesso che, attraverso il metodo sperimentale, cerca di falsificare le proprie ipotesi e le proprie teorie.

In realtà, un simile atteggiamento autocritico è difficile da mantenere, anche perché, per un ricercatore, è molto più gratificante confermare la validità delle proprie ipotesi che falsificarle. Ciononostante, questo approccio critico è considerato talmente importante che vi sono due meccanismi metodologici, fortemente consolidati, finalizzati proprio a rafforzare questo atteggiamento.

#### Il peer reviewing

Uno dei due meccanismi finalizzato a mantenere l’atteggiamento critico è il meccanismo del peer reviewing: prima che un lavoro scientifico venga accettato (e dunque pubblicato su di una rivista scientifica), deve passare al vaglio di altri ricercatori. Questo *esame fra colleghi* avviene in forma anonima, ed è finalizzato proprio a garantire che, prima di venir pubblicato, il lavoro sia analizzato attentamente e con occhio critico per valutarne sia il rispetto dei principi epistemologici e metodologici, di validità che la rilevanza scientifica.

#### Falsificazione e ipotesi nulla

In secondo luogo, l’approccio falsificazionista sta alla base della statistica inferenziale. Come vedremo nei prossimi paragrafi e nel corso dell’intera dispensa, la statistica inferenziale è finalizzata a valutare quanto le misure ottenute siano attribuibili al caso. Nel confronto fra due (o più) variabili, ad esempio, si cerca di capire se fra le variabili vi è una relazione. Per fare questo, si identifica una statistica, ovvero una procedura di calcolo attraverso cui si ottiene un valore numerico. Il fine del processo inferenziale è stabilire se quel valore numerico va attribuito al caso (all’errore di campionamento) o alla relazione fra le variabili.

Per fare questo, si formulano due ipotesi: l’ipotesi nulla ($H_0$) assume che il valore numerico misurato sia attribuibile al caso, e che dunque, dall’analisi fatta, non si possa dedurre che vi sia una relazione. L’ipotesi alternativa ($H_A$) assume invece che il valore numerico non sia attribuibile al caso, e dunque si possa inferire che la relazione esiste.

Ebbene, il processo inferenziale si basa sul rifiuto (ovvero, sulla falsificazione) dell’ipotesi nulla. Se il valore numerico calcolato è superiore (o inferiore, a seconda dei casi) ad un valore critico, si rifiuta l’ipotesi nulla, ovvero si falsifica l’ipotesi che non vi sia relazione fra le variabili. In caso contrario, l’ipotesi nulla **non viene rifiutata**, ma si rifiuta l’ipotesi alternativa.

> In God we trust, all others bring data. – William Edwards Deming

## Principi

Come abbiamo visto, la ricerca scientifica si basa su di una serie di principi epistemologici e metodologici.

-   empiricismo (guardare ai dati);
-   determinismo (assumere la presenza di relazioni causa - effetto);
-   parsimonia (le spiegazioni semplici sono meglio di quelle complicate);
-   preferenza per un approccio scientifico - sperimentale;
-   un *sano* scetticismo;
-   amore per la precisione;
-   indagine basata su teorie e ipotesi;
-   rispetto per i paradigmi teorici;
-   disponibilità a cambiare opinione (e ad ammettere di avere, talvolta, torto);
-   fedeltà alla realtà, ovvero alle osservazioni empiriche;
-   aversione per la superstizione, e preferenza per le spiegazioni scientifiche;
-   *sete di conoscenza*, o più banalmente sana curiosità e voglia di sapere;
-   capacità di sospensione del giudizio;
-   consapevolezza delle proprie assunzioni, e dei limiti (teorici, metodologici, di misurazione);
-   capacità di separare le cose importanti da quelle irrilevanti;
-   rispetto - e attitudine positiva - verso i metodi quantitativi;
-   conoscenza delle basi della statistica e della teoria della probabilità;
-   consapevolezza che la conoscenza è sempre imperfetta e in qualche modo imprecisa.

### Metodo scientifico

Sebbene non esista una ricetta preconfezionata, possiamo semplificare l’approccio scientifico come qualcosa che assomiglia al processo seguente:

1.  osserva un aspetto del mondo
2.  formula un’ipotesi su quell’aspetto
3.  usa la teoria per fare delle previsioni
4.  testa le tue previsioni, attraverso delle osservazioni o, meglio, degli esperimenti
5.  modifica la teoria alla luce dei risultati
6.  ricomincia dal punto 3.

#### Analisi della letteratura

> A month in the laboratory can often save an hour in the library.\
> – F. H. Westheimer

Per trovare una risposta scientificamente plausibile ad un problema:

-   studiare la letteratura: molto probabilmente il problema è già stato affrontato, sono state sviluppate delle teorie, sono stati pubblicati degli esperimenti. Prima di immaginare di iniziare una ricerca, è fondamentale analizzare la letteratura.
-   se dalla letteratura emergono risposte chiare, il processo può fermarsi: abbiamo la risposta che cercavamo.

#### Contribuire alla ricerca

Se dall’analisi della letteratura non emerge una risposta chiara alle domande che ci siamo posti, può aver senso cercare di dare una risposta empirica, adottando il metodo scientifico.

-   partire da ciò che è emerso dallo studio della letteratura;
-   se opportuno, iniziare una fase di osservazione, o una raccolta dati più aperta, meno quantitativa e più qualitativa, per meglio definire il problema;
-   formulare un’ipotesi, plausibilmente all’interno di una teoria;
-   formulare una previsione, basata sull’ipotesi;
-   procedere ad uno studio empirico, possibilmente quantitativo, possibilmente con un disegno di tipo sperimentale;
-   analizzare i dati, possibilmente con l’utilizzo anche di statistiche inferenziali;
-   trarre delle conclusioni.

#### Tipologie di ricerche empiriche

Abbiamo già accennato che l’approccio empirico può essere più rigoroso, quantitativo, oppure privilegiare un aspetto più qualitativo. Semplificando, possiamo elencare le seguenti tipologie di ricerca:

-   osservazione non sistematica: si tratta di osservare un fenomeno, prenderne nota; è utile in una fase iniziale della ricerca, per iniziare ad avere un’idea del fenomeno studiato e formulare le prime ipotesi;
-   osservazione sistematica: il fenomeno non viene solo osservato, ma anche misurato; le dimensioni rilevanti vengono decise in anticipo;\
    event sampling: viene registrato un dato ogni volta che ha luogo un evento; time sampling; viene fatta una osservazione ad ogni intervallo di tempo;\
    l’osservazione, in quanto tale, tende a non modificare né interferire con quello che osserva;
-   esperimento: finalizzato a verificare o falsificare un’ipotesi; implica la manipolazione diretta di una o più variabili (indipendenti), la misura di uno o più variabili dipendenti, e l’analisi dei dati attraverso delle statistiche inferenziali;
-   si definisce quasi-esperimento una situazione empirica in cui le variabili indipendenti non possono essere manipolate dallo sperimentatore.
-   le simulazioni usano modelli fisici o matematici per riprodurre le condizioni di una situazione o di un processo.

## Validità

Il metodo scientifico, e più in particolare l’approccio sperimentale, si basa sull’assunzione che vi sia un legame esplicativo fra ciò che succede nel contesto sperimentale e quello che si intende spiegare.

L’esperimento, in quanto tale, tende a replicare in un setting controllato alcuni aspetti di ciò che avviene nel mondo esterno, per poter verificare se vi è una relazione causale fra due o più variabili.

Per fare questo bisogna ricreare la situazione nel setting, testare la relazione causale, e riportare la relazione all’ambiente originale.

### Presupposti di validità

I presupposti sono:

-   che alcuni aspetti di un fenomeno si possano misurare, se non su tutta la popolazione, almeno su di un campione;
-   che, a partire da queste misurazioni, si possano fare delle analisi statistiche per far emergere delle relazioni o delle differenze;
-   che questi risultati abbiano una significatività statistica;
-   che ciò che si è misurato e che i dati ottenuti abbiano un legame con il fenomeno in questione;
-   che i risultati ottenuti sul campione, nel contesto sperimentale, possano essere generalizzati.

Una ricerca è valida se rispetta questi assunti.

### Tipi di validità

In letteratura si trovano diversi tipi di validità. Ne elenchiamo i più importanti.

#### La validità di costrutto

Si preoccupa di valutare se una scala (o una variabile) misura - o correla - con il costrutto scientifico teorizzato. La validità di costrutto può essere supportata dalla validità **convergente**, che ha luogo quando la misura correla statisticamente con misure correlate teoricamente, e dalla validità **discriminante**, che ha luogo quando vi è una mancata correlazione statistica con misure che la teoria suppone non siano correlate.

#### La validità di contenuto

Si preoccupa che l’esperimento (o le variabili misurate) coprano adeguatamente il soggetto di studio, ed è fortemente legata al design sperimentale.

#### La validità statistica

È legata alla possibilità di trarre delle inferenze dall’analisi statistica, ovvero se le differenze o le associazioni che misuriamo sono statisticamente significative.

#### La validità interna

Vi è validità interna se possiamo assumere che vi sia una relazione causale fra le variabili studiate, ovvero se una correlazione osservata può essere considerata una relazione causale. Può essere assunta solo all’interno di un disegno sperimentale.

#### La validità esterna

Si preoccupa di verificare se le conclusioni valide nel setting sperimentale possono essere generalizzate, alla popolazione o a contesti diversi.

#### Validità e statistica

-   L’analisi dei dati è uno degli strumenti che ci permette di valutare alcuni degli aspetti della validità di un esperimento.
-   L’analisi descrittiva ed esplorativa ci permettono di verificare l’esistenza di una relazione fra variabili.
-   L’analisi inferenziale ci permette di verificare la validità statistica propriamente detta.
-   Le tecniche di campionamento sono finalizzate a massimizzare la validità esterna.
-   Il design sperimentale ha il fine di preservare la validità interna

### Affidabilità

L’affidabilità si riferisce alla qualità del processo di misurazione delle variabili. È legato agli aspetti della ripetibilità della misura e di accuratezza della stessa.

## L’analisi dei dati

### Scopi

L’analisi dei dati è finalizzata a molteplici scopi:

-   descrivere – numericamente e graficamente – una misura relativa ad un campione;
-   fare delle stime – puntuali e ad intervallo – relative a dei parametri della popolazione;
-   calcolare delle relazioni fra due o più variabili, misurate sul campione, e fare delle inferenze in merito alla popolazione di riferimento;
-   fare delle previsioni in merito al valore di una osservazione, non nota, a partire da delle osservazioni note.

Possiamo dunque distinguere fra statistiche descrittive-esplorative e statistiche inferenziali.

### Statistica esplorativa

#### Finalità

Le statistiche descrittive sono finalizzate a:

-   avere una prima visione, qualitativa, delle variabili raccolte;
-   controllare la presenza di errori, ad esempio di data-entry;
-   far emergere outliers e anomalie;
-   valutare qualitativamente ipotesi e assunti, determinare qualitativamente le relazioni fra le variabili;
-   identificare l’entità e la direzione delle relazioni fra le variabili;
-   selezionare i modelli statistici appropriati;

Le statistiche esplorative propriamente dette (Exploratory Data Analysis, EDA) hanno anche altre funzioni:

-   scoprire pattern e strutture implicite;
-   estrarre variabili latenti, o far emergere variabili importanti;
-   sviluppare modelli parsimoniosi (riduzione dello spazio delle variabili);
-   determinare opportuni parametri per ulteriori analisi (es n’ di fattori, n’ di clusters)

#### Tipologie di statistica esplorativa

La statistica esplorativa può essere univariata o multivariata. Inoltre, può utilizzare metodi grafici e metodi non grafici. Spesso, in letteratura, si tende ad usare sia il termine descrittiva che esplorativa, anche se forse ha più senso parlare di statistica esplorativa quando valuta la relazione fra due o più variabili, e descrittiva la statistica non inferenziale univariata.

Mentre l’analisi inferenziale segue la definizione dell’ipotesi di ricerca, l’analisi esplorativa spesso ha luogo prima della definizione del modello teorico e dell’ipotesi di ricerca. Semplificando, nell’analisi inferenziale, la sequenza teorica è problema $\rightarrow$ definizione di un modello (ipotesi) $\rightarrow$ raccolta dei dati $\rightarrow$ analisi $\rightarrow$ eventuali conclusioni

Nell’analisi esplorativa, la sequenza è problema $\rightarrow$ raccolta dei dati $\rightarrow$ analisi esplorativa $\rightarrow$ definizione di un modello (ipotesi) $\rightarrow$ eventuali conclusioni

### Statistica descrittiva univariata

Nella statistica descrittiva univariata (non grafica), si valutano prevalentemente tre aspetti [@WaltenburgMcLauchlan:2010]:

-   le tendenze centrali della distribuzione
-   la dispersione della distribuzione
-   la forma della distribuzione

Gli strumenti e le misure della statistica descrittiva univariata dipendono dalla tipologia della variabile: categoriale-ordinale versus numerica (intervalli, rapporti).

#### Distribuzione

La distribuzione sintetizza la frequenza dei valori o di intervalli di valori di una variabile. La frequenza può essere assoluta (il numero di osservazioni che cadono in quella categoria o che rientrano in quel valore o intervallo) o in termini percentuali.

La distribuzione può essere rappresentata in forma tabellare, oppure con un grafico (tipicamente, un istogramma). Nella forma tabellare, rappresenta una distribuzione di frequenza. Possiamo distinguere

-   frequenze assolute: si contano il numero di volte che un particolare valore è ottenuto nel campione;
-   frequenze relative, proporzioni: frequenze assolute divise per il numero di osservazioni;
-   frequenze percentuali: proporzioni moltiplicate per 100.

Le frequenze sono rappresentate in tabelle di contingenza.

#### Tendenze centrali

La tendenza centrale di una distribuzione è una stima del centro di una distribuzione di valori.

Vi sono tre principali tipologie di stima della tendenza centrale:

-   la moda: il valore (o la categoria) più frequente. Per calcolare la moda, è sufficiente ordinare i punteggi in base alla frequenza, e selezionare il primo.
-   la mediana: il valore che sta a metà quando le osservazioni sono ordinate in base alla variabile. Se il numero di osservazioni è dispari, si calcola la media fra i due valori centrali.
-   la media aritmetica, si calcola sommando i valori e dividendo la somma per il numero di osservazioni.

#### Indici di dispersione

La dispersione si riferisce alla diffusione dei valori intorno alla tendenza centrale. Le due misure più importanti sono

-   il range, ovvero la distanza fra il valore massimo ed il minimo.
-   la deviazione standard misura la variabilità attorno alla media.
-   la distanza interquartilica: corrisponde al range fra il primo e il terzo quartile. Meno soggetto agli outliers.

Non tutti questi indici possono essere applicati a tutte le variabili, e dunque il primo passaggio nella statistica descrittiva è dunque quello di definire le tipologie di variabili studiate.

### Tipologie di variabili

Possiamo distinguere 4 tipologie di variabili:

-   nominali
-   ordinali
-   ad intervalli
-   a rapporti

Nel definire le tipologie di statistiche applicabili, la distinzione più importante è fra variabili categoriali e quantitative (intervalli, rapporti).

#### Scale nominali

Le variabili nominali creano delle categorie, e permettono di classificare le osservazioni all’interno di quelle categorie.

Alle varie categorie non può essere attribuito un ordine, e tantomeno è possibile fare delle operazioni matematiche sulle variabili nominali.

Una variabile dicotomica è un caso speciale di variabile nominale, in cui vi sono soltanto due categorie.

A partire da una variabile nominale è possibile calcolare la frequenza (ovvero il numero di osservazioni classificate in ogni gruppo) e la moda (ovvero il gruppo più numeroso).

#### Scale ordinali

Le variabili ordinali permettono di stabilire un ordine fra gli elementi.

Sotto certi aspetti, costituiscono una estensione delle variabili nominali. Essendo possibile stabilire un ordine, permettono di identificare la posizione di un elemento nel rapporto con gli altri elementi.

Data una variabile ordinale, oltre alla moda, è possibile calcolare i percentili, i quartili, la mediana.

#### Scale ad intervalli

Le variabili ad intervalli non solo possono essere ordinate, ma è possibile fare delle assunzioni in merito alla distanza fra i valori, in quanto la distanza fra ogni valore intero è costante.

È possibile misurare non soltanto la moda e la mediana, ma anche la media aritmetica fra le tendenze centrali; fra le misure di dispersione, possiamo misurare il range, la distanza interquartilica e la deviazione standard.

Le scale a rapporto sono variabili ad intervalli; la loro particolarità è dovuta al fatto che il valore che corrisponde allo zero non è arbitrario, ma assoluto. Ciononostante, generalmente si applicano alle variabili a rapporto le stesse statistiche delle variabili ad intervalli.

### Variabili e statistiche

#### Statistica descrittiva univariata categoriale

Nel caso di variabile categoriale, la rappresentazione non grafica più appropriata è in forma tabellare: si costruisce una tabella, con tante colonne quanti i livelli della variabile. I valori delle celle rappresentano la frequenza delle osservazioni per ogni livello. La frequenza può essere assoluta (il numero di osservazioni) o relativa. Per ottenere la tabella della frequenza relativa si dividono le osservazioni di ogni livello per il numero di osservazioni totale.

L’unica misura della tendenza centrale appropriata per le scale nominali è la moda, ovvero il livello con frequenza più alta.

Graficamente, una variabile categoriale può essere rappresentata attraverso un grafico a barre.

Se il numero di livelli è basso, può essere utile anche la rappresentazione del grafico a torta.

#### Statistica descrittiva univariata, variabili ordinali

Nel caso di variabili ordinali, oltre alla moda e al numero di livelli, possiamo calcolare:

-   l’indice di centralità della mediana;
-   indici di dispersione quali il range e i percentili; di particolare interesse i quartili e la distanza interquartilica.
-   anche nel caso di variabili ordinali, se il numero di livelli è relativamente basso, può essere utile creare la tabella delle frequenze, assolute o relative.
-   La rappresentazione grafica più appropriata è il grafico a barre, a patto che l’ordine degli elementi grafici rispetti l’ordine delle categorie.

#### Statistica descrittiva univariata, variabili numeriche

-   nelle variabili ad intervalli (o a rapporti), oltre alla moda e alla mediana si calcola l’indice di centralità della media.
-   oltre al range, ai percentili ed ai quartili, si calcola l’indice di dispersione della varianza (e della deviazione standard).
-   nell’analisi della forma della distribuzione, l’aspetto più importante consiste nel valutare se la distribuzione osservata approssima una distribuzione teorica, tipicamente la distribuzione normale. Nel caso, è possibile calcolare la simmetria e la kurtosi della curva di distribuzione.

#### Statistica grafica univariata, variabili numeriche

-   per rappresentare graficamente la distribuzione, si utilizzano l’istogramma e il grafico della distribuzione ottenuto attraverso il metodo del kernel.
-   attraverso il boxplot è possibile rappresentare la mediana, i quartili ed il range di una distribuzione numerica. È possibile inoltre valutare la presenza di outliers, ovvero di osservazioni collocate ai margini della distribuzione osservata.
-   usando il grafico qqnorm (o qqplot) e la funzione qqline è possibile confrontare la distribuzione osservata con la distribuzione teorica normale.

### Valutazione della normalità, trasformazioni

#### Test di normalità

Poiché le statistiche inferenziali parametriche assumono una distribuzione delle osservazioni di tipo normale, è generalmente opportuno valutare la distribuzione osservata di una variabile non soltanto attraverso metodi grafici e descrittivi, ma anche attraverso dei test di normalità. In questa dispensa, utilizzeremo due di questi test:

-   Il test di *Kolmogorov-Smirnov* permette di confrontare due distribuzioni arbitrarie, e può essere usato per il confronto fra la distribuzione osservata e la distribuzione normale;
-   Il test di normalità *Shapiro-Wilk* è finalizzato a valutare la normalità della distribuzione osservata.

Le due misure possono dare risultati differenti. Risulta pertanto necessario un processo di valutazione che tenga conto sia dei risultati dei test che dell’analisi grafica della distribuzione.

Questa regola pratica vale in ogni ambito della ricerca e dell’analisi dei dati: la metodologia ci indica delle procedure che è opportuno seguire, per minimizzare il rischio di errori che mettano a repentaglio affidabilità e validità della ricerca.

Le procedure, però, non vanno seguite pedissequamente. Conoscere i princîpi e gli assunti dell’analisi dei dati ci permette di fare delle inferenze ragionevolmente robuste anche nei casi, e sono molti, in cui non è possibile una applicazione meccanica della procedura.

### Statistiche esplorative bivariate

Le statistiche esplorative multivariate hanno la finalità di mettere in relazione due o più variabili.

Le statistiche grafiche tendono a limitarsi prevalentemente al confronto di due variabili alla volta, in quanto questi confronti sono più facili da rappresentare e più immediati da leggere.

#### Variabili numeriche: grafico di dispersione

Nel caso di confronto fra due variabili numeriche, la rappresentazione grafica più appropriata è il grafico di dispersione, che mappa le osservazioni delle due variabili sulle due dimensioni x e y.

La linea di regressione, inoltre, ci permette di visualizzare il modello di regressione lineare.

#### Variabili categoriali: mosaic plot

Attraverso il mosaic plot è possibile rappresentare graficamente la relazione fra due variabili di tipo categoriale, nominale o ordinale.

Per rappresentare numericamente il rapporto fra due variabili categoriali si usa invece la tabella delle frequenze (assolute o relative). La tabella, di dimensioni $r*c$, dove r è il numero di livelli di una variabile, c il numero di livelli dell’altra.

#### Variabile categoriale vs variabile numerica

Nel caso si debbano confrontare graficamente una variabile numerica su di una variabile categoriale, è possibile utilizzare nuovamente il boxplot, disegnando tanti boxplot quanti sono i gruppi della variabile categoriale.

Una seconda possibilità è quella di un grafico a barre, dove ogni barra rappresenta la media di ogni gruppo. Un’alternativa grafica consiste nel sostituire le barre con delle linee che congiungono i punti che rappresentano le medie.

Queste rappresentazioni possono essere utilizzate anche quando le variabili categoriali (indipendenti) sono due.

## Statistica inferenziale

### Finalità

Il fine dell’analisi inferenziale è quello – banalmente – di fare delle inferenze su di una popolazione a partire dalle osservazioni di un campione.

Il fine dell’analisi inferenziale univariata, è quello di stimare il valore di un parametro della popolazione a partire da una statistica calcolata sul campione.

Il fine dell’analisi inferenziale bivariata è quello di stimare la significatività di una relazione fra due variabili. Le analisi multivariate sono sostanzialmente un’estensione dell’analisi bivariata.

Nel confronto fra le variabili, possiamo determinare

-   correlazioni fra variabili
-   differenze fra gruppi
-   determinazione di relazioni
-   stima di effetti
-   predizioni basate su analisi della regressione.

#### Analisi inferenziale univariata

La finalità è quella di stimare il parametro di una popolazione a partire dalla statistica corrispondente, calcolata sul campione. Generalmente, il parametro stimato è la media della popolazione, ma si usa anche per stimarne la varianza o la mediana.

Poiché queste statistiche sono soggette all’errore di campionamento, nell’analisi inferenziale si calcola anche l’intervallo di confidenza, ovvero la forbice entro cui si stima che il parametro oggetto di indagine si collochi.

#### Analisi inferenziale bivariata

Lo scopo di questo tipo di analisi è quello di verificare che vi sia una relazione statisticamente significativa fra le due variabili.

L’approccio comune alle analisi bivariate è quello di identificare una statistica capace di misurare la relazione, applicare la statistica sulle variabili in oggetto, e confrontare il valore con la distribuzione dell’errore di quella statistica.

Se il valore numerico della statistica cade all’interno della distribuzione di errore, si assume che quella relazione non sia statisticamente significativa.

## Gli errori

Il fine dell’analisi inferenziale è quello di trarre delle conclusioni in merito a dei parametri di una o più popolazioni. Per fare questo, si potrebbe voler misurare i parametri della popolazione di interesse, calcolarne le statistiche appropriate, e trarne le debite inferenze.

Testare l’intera popolazione è però generalmente impossibile, per due ordini di motivi.

-   Il motivo più ovvio è di tipo pratico: se la popolazione è molto numerosa, testarla completamente diventa eccessivamente costoso.
-   Vi è inoltre un secondo motivo: a volte, la popolazione di riferimento è teorica. Ad esempio, potremmo voler fare delle inferenze sulla depressione post partum; in questo caso, la popolazione di riferimento sono tutte le donne che hanno partorito da meno di 3, 4 mesi. Ma anche se riuscissimo a testare tutte le partorienti d’Italia per un intero anno solare, vorremmo che i risultati ci permettessero di fare delle inferenze anche sulle donne che partoriranno fra due anni. La popolazione reale di quest’anno, dunque, è un sottoinsieme della popolazione teorica che include le donne che partoriranno nei prossimi anni.

Appare dunque chiaro che, tranne alcune eccezioni, testare l’intera popolazione è generalmente impossibile. A questo punto, diventa necessario testare soltanto un sottoinsieme della popolazione, ovvero un campione (sample, in inglese).

Semplificando, la logica sottostante l’analisi dei dati è sostanzialmente la seguente:

-   si identifica un problema
-   si identifica una popolazione
-   si identifica una dimensione pertinente
-   si estrae un campione
-   si misura la dimensione sul campione
-   a partire dalla statistica sul campione, si traggono inferenze sul parametro di popolazione
-   si traggono delle inferenze sui risultati

Vi è, dunque, un passaggio logico: popolazione - campione, misura sul campione - generalizzazione alla popolazione. Abbiamo visto che, affinché questi passaggi portino a risultati accettabili, è necessario preservare dei criteri di validità. Più in particolare, è necessario minimizzare e gestire alcuni errori che possono influire sull’analisi.

### Tipi di errore

L’analisi inferenziale si basa sulla consapevolezza che i processi di campionamento, misurazione ed analisi sono soggetti ad errori. Il fine della metodologia è quello di minimizzare e, quando possibile, escludere gli errori. Il fine dell’inferenza è quello di misurare gli errori, valutare se i risultati ottenuti sono da attribuire o meno agli errori, e stimare il rischio che il processo decisionale dell’inferenza sia scorretto.

Conoscere le tipologie di errori e i metodi per minimizzarli ed evitarli è dunque di centrale importanza nella metodologia e nell’analisi.

Sono numerosi gli errori che possono influire sul processo inferenziale. Ricordiamone alcuni.

-   Errore di **campionamento**: il campione non produrrà esattamente gli stessi valori che si osserverebbero misurando l’intera popolazione.
-   In un esperimento, errore di **assegnamento**: le differenze misurate fra i gruppi sperimentali (e di controllo) potrebbero essere dovute non alla condizione sperimentale, ma a differenze pre-esistenti fra i gruppi creati
-   Errore di **misurazione** (affidabilità): la misurazione della variabile può essere non accurata, e dunque può produrre risultati parzialmente non corretti.

Più in generale, si definisce errore la differenza fra una misura di un parametro ed il valore reale del parametro stesso. Questa differenza può essere casuale o sistematica. Per capire la differenza, è necessario pensare a numerose misure, e dunque al ripetersi dell’errore. Se l’errore è casuale, la media degli errori (ovvero la media delle differenze) tende ad essere pari a zero. Viceversa, l’errore è sistematico se la media tende ad un valore diverso da zero.

Gli errori sistematici sono i più *pericolosi*, in quanto possono indurre il ricercatore a conclusioni errate e sono difficili da far emergere e da correggere attraverso gli strumenti statistici. Gli errori sistematici possono essere minimizzati soltanto attraverso un design rigoroso ed una raccolta ed elaborazione dei dati scrupolosa.

Il problema del campionamento è che, se fatto in maniera scorretta, può indurre ad errori sistematici.

## Campionamento

Viene definito campionamento il processo di selezione del sottoinsieme di unità della popolazione da studiare, per misurarne le caratteristiche di interesse.

La notizia positiva è che, se il campionamento viene effettuato in maniera corretta, le caratteristiche misurate sul campione tendono ad assomigliare alle caratteristiche (parametri) della popolazione.\
La notizia negativa è che, nonostante la somiglianza, le statistiche sul campione sono in qualche modo diverse dai parametri della popolazione. Questa differenza va attribuita alla variabilità campionaria: se noi selezioniamo due campioni distinti da una stessa popolazione, otteniamo statistiche diverse. Queste differenze sono definite anche errore di campionamento.

### Campionamento rappresentativo

Per evitare errori sistematici dovuti al campione, è necessario che il campione sia rappresentativo della popolazione.

La tipologia di campionamento che meglio garantisce la rappresentatività della popolazione è il campionamento casuale: le unità del campione vengono scelte casualmente dalla popolazione. In alcuni casi si utilizza una forma di campionamento stratificata, nelle circostanze in cui si voglia garantire la rappresentatività di piccoli sottogruppi di popolazione.

Viceversa, metodi di campionamento non casuali (come i campionamenti di convenienza) rischiano di introdurre degli errori sistematici nella statistica [@Akritas:2008].

#### Missing

Un problema di non facile soluzione emerge quando una parte non trascurabile del campione selezionato non si presta alla misurazione. Se i missing si distribuiscono in maniera uniforme fra il campione, l’impatto di questi dati mancanti risulta abbastanza circoscritto.

Se, al contrario, i missing sono più frequenti in alcuni strati della popolazione piuttosto che in altri, è forte il rischio di incorrere in un errore sistematico.

### Errori casuali

Una parte di errore, però, non può essere evitata. Se questi errori non sono sistematici, ma distribuiti casualmente, i metodi statistici ci permettono di misurarli, di valutarne l’impatto, e di calcolare la probabilità che i risultati da noi ottenuti siano o meno attribuibili al caso.

La funzione della statistica inferenziale è di fare delle stime, relative ai parametri della popolazione, partendo dalle statistiche dei campioni, che tengano conto della variabilità campionaria. L’analisi inferenziale offre una serie di strumenti che permettano di:

-   fare delle stime sui parametri di una popolazione
-   determinare se i parametri di due o più popolazioni sono significativamente diversi
-   valutare se due o più parametri relativi ad una popolazione sono fra loro legati
-   fare delle previsioni

L’analisi inferenziale fa delle stime, di tipo puntuale e intervallare, su determinati parametri della popolazione, testa delle ipotesi, valuta l’accuratezza delle proprie previsioni e determina il rischio che le stime, le ipotesi accettate e le previsioni risultino errate.

### Intervalli di confidenza

Un corretto campionamento minimizza l’incidenza degli errori sistematici, ma non elimina l’errore casuale.

Il valore della statistica sul campione, infatti, è una approssimazione del valore del parametro della popolazione. Più precisamente, la media del campione costituisce una *stima puntuale* della media della popolazione. Sappiamo, però, che questa stima sarà – quasi sicuramente – leggermente sbagliata. Conoscendo soltanto la stima puntuale, non sappiamo quanto questa stima sia affidabile, e quale sia il probabile range di errore.

Il calcolo dell’intervallo di confidenza è finalizzato proprio a calcolare il range entro cui il valore del parametro di popolazione **dovrebbe** cadere.

Un intervallo di confidenza si basa su una percentuale - prestabilita - di confidenza. Generalmente, si considera accettabile una percentuale del 95%.

Per meglio capire la percentuale dell’intervallo di confidenza, partiamo da una osservazione. Se estraiamo 2 campioni diversi dalla stessa popolazione, e misuriamo la stessa variabile sui due campioni, otterremo valori (più o meno) diversi.

Immaginiamo ora di estrarre 101 campioni dalla popolazione. Usiamo il primo campione per misurare il parametro della popolazione, e l’intervallo di confidenza. Un intervallo di confidenza del 95% significa che, se misuriamo la stessa statistica sugli altri 100 campioni, ci aspettiamo che – **approssimativamente** – 95 di loro cadano entro l’intervallo di confidenza.

Più “stretto” l’intervallo di confidenza, più alta la precisione.\
Un intervallo di confidenza molto largo lascia intendere che le dimensioni del campione sono inadeguate. L’intervallo di confidenza verrà descritto più dettagliatamente nella sezione \[section:simula\_confidenza\]

### Testare un’ipotesi

Nel test di ipotesi, si identificano un’ipotesi nulla e un’ipotesi alternativa; si fanno delle misurazioni e si calcola una statistica; se la statistica cade all’interno della regione di accettazione (basata sulla distribuzione dell’errore campionario), l’ipotesi nulla non viene rifiutata. In caso contrario, l’ipotesi nulla viene rifiutata, e si accetta l’ipotesi alternativa. Il test di ipotesi si pone la questione: “i risultati che abbiamo ottenuto possono essere attribuiti al caso?” Il primo passo, è quello di tradurre il problema scientifico che ci siamo posti nei termini delle due ipotesi: l’ipotesi nulla e l’ipotesi alternativa.

-   L’ipotesi nulla, $H_0$, assume che il risultato non sia significativo, ovvero che sia da attribuire al caso.
-   L’ipotesi alternativa $H_1$ o $H_A$, sostiene che il risultato della statistica non possa essere attribuito al caso, ma che sia da attribuire ad una relazione inerente la popolazione, sia questa una differenza o una relazione.

Il secondo passo, è identificare una statistica che sia capace di misurare la differenza (o la relazione) all’interno del campione, ed applicarla ai dati raccolti.

Il terzo passo è confrontare il valore della statistica con la **corrispondente distribuzione di errore**. Informalmente, possiamo dire che più il valore della statistica si colloca *ai margini* della distribuzione di errore, meno è probabile che la differenza (o la relazione) misurata siano attribuibili al caso. Questa probabilità può essere stimata in base alla distribuzione dell’errore, e costituisce il p-value, valore su cui si basa la decisione finale: se il p-value risulta inferiore ad un livello di soglia accettabile, definito $\alpha$, si rifiuta l’ipotesi nulla, e si accetta l’ipotesi alternativa. In caso contrario, non si rifiuta l’ipotesi nulla.

#### L’ipotesi nulla

Poiché i concetti di ipotesi nulla, ipotesi alternativa e p-value sono molto importanti nella statistica inferenziale ma sono spesso difficili da comprendere, ci soffermiamo ancora su questi concetti.

L’ipotesi nulla e l’ipotesi alternativa sono alla base del test di ipotesi, che costituisce il fine della statistica inferenziale, che si propone di capire (e di decidere) se i risultati ottenuti siano da attribuire, o meno, al caso.

L’esempio più tipico è il disegno sperimentale dove i partecipanti sono assegnati casualmente a due gruppi, il gruppo sperimentale e quello di controllo. Al gruppo sperimentale viene somministrato un *trattamento*, al gruppo di controllo no (oppure, viene somministrato il *placebo*). Viene definita una misura, capace di valutare l’outcome, il risultato del trattamento. Si calcola l’appropriata statistica (ad esempio la media) dei due gruppi sperimentali, e si calcola la differenza fra le due medie.

Se la metodologia sperimentale è stata seguita correttamente, la differenza fra le due medie può essere attribuita soltanto a due possibili cause: il trattamento, o il caso.\
L’ipotesi nulla assume che la statistica misurata (in questo caso, la differenza) sia attribuibile al caso, ovvero che la *vera* differenza fra la media dei due gruppi sia pari a zero.\
L’ipotesi alternativa assume che la differenza non possa essere attribuita al caso e, per esclusione, sia attribuibile al trattamento.

L’ipotesi nulla viene rifiutata se la differenza fra le medie dei due gruppi è tale da non poter essere attribuita al caso, ovvero se si discosta significativamente dalla distribuzione dell’errore di campionamento. Formalmente, si parla di rifiuto e *non rifiuto* dell’ipotesi nulla. Non è formalmente corretto parlare di accettazione dell’ipotesi nulla. Cerchiamo di capire il perché.\
L’ipotesi nulla assume che il valore della statistica sia da attribuire al caso. Se il valore è esterno alla *regione di accettazione* non possiamo attribuire il risultato al caso, e dunque dobbiamo rifiutare l’ipotesi nulla, ed accettare l’ipotesi alternativa (il risultato non è attribuibile al caso).

Se il valore della statistica cade all’interno della *regione di accettazione*, **non possiamo escludere** che il risultato sia attribuibile al caso. Questo però non dimostra che la *vera* misura sia pari a zero. Per quanto ne sappiamo, la *vera* misura potrebbe essere comunque differente da zero. Poiché, però, la differenza misurata potrebbe essere attribuita al caso, tutto quello che possiamo dire è che non si può escludere che la differenza sia dovuta al caso. L’ipotesi nulla non è falsificata (e dunque non viene rifiutata) ma nemmeno verificata (in quanto non sappiamo se la *vera* differenza sia davvero pari a zero.

Il test di ipotesi, dunque, si basa su quell’atteggiamento di tipo falsificazionista introdotto qualche paragrafo sopra.

#### Il p-value

Il p-value è la risposta alla domanda “assumendo che l’ipotesi nulla sia vera, qual è la probabilità di osservare un valore altrettanto o più estremo di quello ottenuto?”

Il p-value è una misura dell’evidenza contraria all’ipotesi nulla: più basso il p-value, maggiore l’evidenza contraria all’ipotesi nulla. Un p-value basso indica una maggiore sicurezza nel rigettare l’ipotesi nulla.

Il p-value è *la probabilità che l’errore campionario possa assumere un valore superiore al valore osservato*. Detto in altri termini, il p-value ci dice la probabilità di compiere un errore di tipo I rifiutando l’ipotesi nulla.

Coerentemente con l’atteggiamento falsificazionista, il p-value può essere usato solo come evidenza **contro** l’ipotesi nulla, non a favore di un’ipotesi. Un p-value alto non ci permette di trarre alcuna conclusione: “*Absence of evidence is not the evidence of absence*”.

In ambito applicativo, non è detto che una significatività statistica abbia reali implicazioni pratiche. In clinica, ad esempio, una differenza statisticamente significativa può non essere clinicamente significativa. Inoltre, il p-value non dice nulla sull’entità della differenza (o dell’effetto)

#### P-value e $\alpha$

La decisione sul rifiuto o meno dell’ipotesi nulla si basa sul confronto fra il p-value e la soglia $\alpha$: se $p <  \alpha$ si rifiuta l’ipotesi nulla, altrimenti no.

$\alpha$ è anche il livello di significatività del test. Generalmente, i valori più comunemente utilizzati sono $\alpha$ = 0.05 e $\alpha$ = 0.01.

#### L’ipotesi alternativa

L’ipotesi alternativa può essere ad una o a due code (**mono- o bidirezionale**). Nell’ipotesi a due code assume l’esistenza di un effetto o una differenza, ma senza specificare la direzione.\
Nell’ipotesi ad una coda, viene specificata anche la direzione attesa della differenza.

### Processo decisionale

Possiamo dunque riassumere il processo decisionale del test d’ipotesi.

-   Si parte, concettualmente, dall’ipotesi nulla;
-   si definisce l’ipotesi alternativa – generalmente, l’ipotesi a supporto della teoria;
-   si definisce e si calcola la statistica test opportuna sulla variabile, misurata sul campione;
-   si definisce l’errore di tipo I che si ritiene accettabile (ovvero, il valore $\alpha$);
-   si calcola la *regione di rifiuto* dell’ipotesi nulla o, alternativamente, il p-value;
-   la decisione finale si basa valutando se la misura della statistica cade all’interno o all’esterno della regione di accettazione dell’ipotesi; se all’esterno, si rifiuta l’ipotesi nulla, e si accetta l’ipotesi alternativa; se all’interno, non si rifiuta l’ipotesi nulla, ma quella alternativa;
-   lo stesso risultato può essere ottenuto confrontando il p-value con $\alpha$: se $p < \alpha$ si rifiuta l’ipotesi nulla, altrimenti no.

### Scegliere la statistica appropriata

Per decidere quale tipo di statistica può essere applicata, è necessario definire:

-   il numero di variabili in gioco (una, due, più di due)
-   la tipologia delle variabili (nominale o numerica)
-   il tipo di ipotesi testata: cerchiamo una relazione, una differenza, una previsione

#### Numero di variabili

-   Statistiche uni-variate
-   Statistiche bi-variate
-   Statistiche multi-variate

#### Tipi di variabili e statistica

La tipologia di statistica inferenziale da applicare si basa sulla tipologia di variabili. Come abbiamo visto, possiamo distinguere fra variabili categoriali, ordinali, ad intervalli e a rapporti.

Queste quattro tipologie possono essere raggruppate in variabili nominali (categoriali e, generalmente, ordinali) e variabili numeriche (a intervalli, a rapporti).

La tipologia di statistica che può essere applicata si basa sulla tipologia delle variabili indipendenti e dipendenti.

#### Statistiche bivariate

                             dipendente numerica         dipendente categoriale
  -------------------------- --------------------------- ---------------------------------------
  indipendente numerica      correlazione, regressione   analisi discriminante, regr. logistica
  indipendente categoriale   t-test, ANOVA               chi quadro

## Esercizi

### Genere e retribuzione

Domanda: vi è una differenza di retribuzione fra maschi e femmine?

-   qual è la variabile indipendente? Di che tipo è?

-   qual è la variabile dipendente? Di che tipo è?

-   che tipo di statistica si applica?

##### Spettatori e pubblicità

Domanda: C’è relazione fra il numero di persone che vanno a vedere un film ed i soldi spesi per pubblicizzare la pellicola?

-   qual è la variabile indipendente? Di che tipo è?

-   qual è la variabile dipendente? Di che tipo è?

-   che tipo di statistica si applica?

##### Antidepressivi e stato depressivo

Domanda: La somministrazione di un antidepressivo è efficace nel curare la depressione?

-   qual è la variabile indipendente? Di che tipo è?

-   qual è la variabile dipendente? Di che tipo è?

-   che tipo di statistica si applica?

##### Genere e facoltà

Domanda: c’è un rapporto fra la scelta di un tipo di facoltà (umanistica, scientifica) di uno studente ed il suo genere?

-   qual è la variabile indipendente? Di che tipo è?

-   qual è la variabile dipendente? Di che tipo è?

-   che tipo di statistica si applica?

##### Nazionalità e caffè

Domanda: c’è un rapporto fra la nazionalità delle persone ed il loro consumo di caffè?

-   qual è la variabile indipendente? Di che tipo è?

-   qual è la variabile dipendente? Di che tipo è?

-   che tipo di statistica si applica?

##### Stato civile e genitorialità

Domanda: c’è un rapporto fra lo stato civile di una persona ed il fatto che abbia o non abbia figli?

-   qual è la variabile indipendente? Di che tipo è?

-   qual è la variabile dipendente? Di che tipo è?

-   che tipo di statistica si applica?


